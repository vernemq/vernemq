%% Copyright 2018 Erlio GmbH Basel Switzerland (http://erl.io)
%%
%% Licensed under the Apache License, Version 2.0 (the "License");
%% you may not use this file except in compliance with the License.
%% You may obtain a copy of the License at
%%
%%     http://www.apache.org/licenses/LICENSE-2.0
%%
%% Unless required by applicable law or agreed to in writing, software
%% distributed under the License is distributed on an "AS IS" BASIS,
%% WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
%% See the License for the specific language governing permissions and
%% limitations under the License.

-module(vmq_queue).
-include_lib("vmq_commons/include/vmq_types.hrl").
-include("vmq_server.hrl").

-behaviour(gen_fsm).

-ifdef(nowarn_gen_fsm).
-compile([
    {nowarn_deprecated_function, [
        {gen_fsm, start_link, 3},
        {gen_fsm, reply, 2},
        {gen_fsm, send_event, 2},
        {gen_fsm, sync_send_event, 3},
        {gen_fsm, send_all_state_event, 2},
        {gen_fsm, sync_send_all_state_event, 3},
        {gen_fsm, send_event_after, 2},
        {gen_fsm, cancel_timer, 1}
    ]}
]).
-endif.

%% API functions
-export([
    start_link/2,
    active/1,
    notify/1,
    notify_recv/1,
    enqueue/2,
    status/1,
    info/1,
    add_session/3,
    get_sessions/1,
    set_opts/2,
    get_opts/1,
    default_opts/0,
    set_last_waiting_acks/3,
    enqueue_many/2,
    enqueue_many/3,
    migrate/2,
    cleanup/2,
    force_disconnect/2,
    force_disconnect/3,
    set_delayed_will/3
]).

-export([
    online/2, online/3,
    offline/2, offline/3,
    wait_for_offline/2, wait_for_offline/3,
    drain/2, drain/3
]).

%% gen_server callbacks
-export([
    init/1,
    handle_sync_event/4,
    handle_event/3,
    handle_info/3,
    terminate/3,
    code_change/4
]).

-record(queue, {
    queue = queue:new(),
    backup = queue:new(),
    type = fifo,
    max,
    size = 0,
    drop = 0
}).

-record(session, {
    pid,
    cleanup_on_disconnect,
    status = notify,
    queue = #queue{},
    started_at :: vmq_time:timestamp(),
    queue_to_session_batch_size :: non_neg_integer()
}).

-record(state, {
    id,
    offline = #queue{},
    deliver_mode = fanout,
    sessions = maps:new(),
    expiry_timer :: undefined | reference(),
    drain_time,
    drain_over_timer,
    drain_pending_batch :: undefined | {reference(), reference(), queue:new()},
    max_msgs_per_drain_step,
    waiting_call,
    opts,
    delayed_will ::
        {Delay :: non_neg_integer(), Fun :: function()}
        | undefined,
    delayed_will_timer :: reference() | undefined,
    started_at :: vmq_time:timestamp(),
    initial_msg_id = 1 :: msg_id()
}).

-type state() :: #state{}.

%%%===================================================================
%%% API functions
%%%===================================================================

-spec start_link(SubscriberId :: subscriber_id(), Clean :: boolean()) ->
    {ok, Pid :: pid()} | ignore | {error, Error :: term()}.
start_link(SubscriberId, Clean) ->
    gen_fsm:start_link(?MODULE, [SubscriberId, Clean], []).

active(Queue) when is_pid(Queue) ->
    gen_fsm:send_event(Queue, {change_state, active, self()}).

notify(Queue) when is_pid(Queue) ->
    gen_fsm:send_event(Queue, {change_state, notify, self()}).

notify_recv(Queue) when is_pid(Queue) ->
    gen_fsm:send_event(Queue, {notify_recv, self()}).

enqueue(Queue, Msg) when is_pid(Queue) ->
    gen_fsm:send_event(Queue, {enqueue, to_internal(Msg)}).

enqueue_many(Queue, Msgs) when is_pid(Queue) and is_list(Msgs) ->
    NMsgs = lists:map(fun to_internal/1, Msgs),
    gen_fsm:sync_send_event(Queue, {enqueue_many, NMsgs}, infinity).

enqueue_many(Queue, Msgs, Opts) when is_pid(Queue), is_list(Msgs), is_map(Opts) ->
    NMsgs = lists:map(fun to_internal/1, Msgs),
    gen_fsm:sync_send_event(Queue, {enqueue_many, NMsgs, Opts}, infinity).

-spec add_session(pid(), pid(), map()) ->
    {ok, #{initial_msg_id := msg_id()}}
    | {error, any()}.
add_session(Queue, SessionPid, Opts) when is_pid(Queue) ->
    gen_fsm:sync_send_event(Queue, {add_session, SessionPid, Opts}, infinity).

get_sessions(Queue) when is_pid(Queue) ->
    gen_fsm:sync_send_all_state_event(Queue, get_sessions, infinity).

set_opts(Queue, Opts) when is_pid(Queue) ->
    gen_fsm:sync_send_event(Queue, {set_opts, self(), Opts}, infinity).

get_opts(Queue) when is_pid(Queue) ->
    save_sync_send_all_state_event(Queue, get_opts).

force_disconnect(Queue, Reason) when is_pid(Queue) ->
    force_disconnect(Queue, Reason, false).
force_disconnect(Queue, Reason, DoCleanup) when is_pid(Queue) and is_boolean(DoCleanup) ->
    gen_fsm:sync_send_all_state_event(Queue, {force_disconnect, Reason, DoCleanup}, infinity).

set_delayed_will(Queue, Fun, Delay) when is_pid(Queue) ->
    gen_fsm:sync_send_all_state_event(Queue, {set_delayed_will, Fun, Delay}, infinity).

set_last_waiting_acks(Queue, WAcks, NextMsgId) ->
    gen_fsm:sync_send_event(Queue, {set_last_waiting_acks, WAcks, NextMsgId}, infinity).

migrate(Queue, Queue) ->
    %% this scenario can happen, due to the eventual migration kickoff
    ok;
migrate(Queue, OtherQueue) ->
    %% Migrate Messages of 'Queue' to 'OtherQueue'
    %% -------------------------------------------
    save_sync_send_event(Queue, {migrate, OtherQueue}).

cleanup(Queue, Reason) ->
    save_sync_send_event(Queue, {cleanup, Reason}).

status(Queue) ->
    gen_fsm:sync_send_all_state_event(Queue, status, infinity).

info(Queue) ->
    save_sync_send_all_state_event(Queue, info).

save_sync_send_event(Queue, Event) ->
    case catch gen_fsm:sync_send_event(Queue, Event, infinity) of
        {'EXIT', {normal, _}} ->
            ok;
        {'EXIT', {noproc, _}} ->
            ok;
        {'EXIT', Reason} ->
            exit(Reason);
        Ret ->
            Ret
    end.

save_sync_send_all_state_event(Queue, Event) ->
    case catch gen_fsm:sync_send_all_state_event(Queue, Event, infinity) of
        {'EXIT', {normal, _}} ->
            {error, noproc};
        {'EXIT', {noproc, _}} ->
            {error, noproc};
        {'EXIT', Reason} ->
            exit(Reason);
        Ret ->
            Ret
    end.

default_opts() ->
    #{
        allow_multiple_sessions => vmq_config:get_env(allow_multiple_sessions),
        max_online_messages => vmq_config:get_env(max_online_messages),
        max_offline_messages => vmq_config:get_env(max_offline_messages),
        queue_deliver_mode => vmq_config:get_env(queue_deliver_mode),
        queue_type => vmq_config:get_env(queue_type),
        max_drain_time => vmq_config:get_env(max_drain_time),
        max_msgs_per_drain_step => vmq_config:get_env(max_msgs_per_drain_step),
        is_plugin => false
    }.

%%%===================================================================
%%% gen_fsm state callbacks
%%%===================================================================
online({change_state, NewSessionState, SessionPid}, State) ->
    {next_state, online, change_session_state(NewSessionState, SessionPid, State)};
online({notify_recv, SessionPid}, #state{id = SId, sessions = Sessions} = State) ->
    #session{queue = #queue{backup = Backup} = Queue} = Session = maps:get(SessionPid, Sessions),
    cleanup_queue(SId, Backup),
    NewSessions = maps:update(
        SessionPid,
        Session#session{queue = Queue#queue{backup = queue:new()}},
        Sessions
    ),
    _ = vmq_metrics:incr_queue_out(queue:len(Backup)),
    {next_state, online, State#state{sessions = NewSessions}};
online({enqueue, Msg}, State) ->
    _ = vmq_metrics:incr_queue_in(),
    {next_state, online, insert(Msg, State)};
online(Event, State) ->
    lager:error("got unknown event in online state ~p", [Event]),
    {next_state, online, State}.

online({set_opts, SessionPid, Opts}, _From, #state{opts = OldOpts} = State) ->
    MergedOpts = maps:merge(OldOpts, Opts),
    NewState1 = set_general_opts(MergedOpts, State#state{opts = MergedOpts}),
    NewState2 = set_session_opts(SessionPid, MergedOpts, NewState1),
    {reply, ok, online, NewState2};
online({add_session, SessionPid, #{allow_multiple_sessions := true} = Opts}, _From, State0) ->
    %% allow multiple sessions per queue
    RetOpts = #{initial_msg_id => State0#state.initial_msg_id},
    State1 = unset_timers(add_session_(SessionPid, Opts, State0)),
    {reply, {ok, RetOpts}, online, State1};
online({add_session, SessionPid, #{allow_multiple_sessions := false} = Opts}, From, State) when
    State#state.waiting_call == undefined
->
    %% forbid multiple sessions per queue,
    %% we've to disconnect currently attached sessions
    %% and wait with the reply until all the sessions
    %% have been disconnected
    #state{id = SubscriberId} = State,
    lager:debug("client ~p disconnected due to multiple sessions not allowed", [SubscriberId]),
    disconnect_sessions(?SESSION_TAKEN_OVER, State),
    {next_state, state_change(add_session, online, wait_for_offline), State#state{
        waiting_call = {add_session, SessionPid, Opts, From}
    }};
online({migrate, OtherQueue}, From, State) when
    State#state.waiting_call == undefined
->
    disconnect_sessions(?DISCONNECT_MIGRATION, State),
    {next_state, state_change(migrate, online, wait_for_offline), State#state{
        waiting_call = {migrate, OtherQueue, From}
    }};
online({set_last_waiting_acks, WAcks, NextMsgId}, _From, State) ->
    {reply, ok, online, handle_waiting_acks_and_msgs(WAcks, NextMsgId, State)};
online({enqueue_many, Msgs}, _From, State) ->
    _ = vmq_metrics:incr_queue_in(length(Msgs)),
    {reply, ok, online, insert_many(Msgs, State)};
online({enqueue_many, Msgs, Opts}, _From, State) ->
    enqueue_many_(Msgs, online, Opts, State);
online({cleanup, Reason}, From, State) when
    State#state.waiting_call == undefined
->
    disconnect_sessions(Reason, State),
    {next_state, state_change(cleanup, online, wait_for_offline), State#state{
        waiting_call = {{cleanup, Reason}, From}
    }};
online(Event, _From, State) ->
    lager:error("got unknown sync event in online state ~p", [Event]),
    {reply, {error, online}, State}.

wait_for_offline({enqueue, Msg}, State) ->
    _ = vmq_metrics:incr_queue_in(),
    {next_state, wait_for_offline, insert(Msg, State)};
wait_for_offline(Event, State) ->
    lager:error("got unknown event in wait_for_offline state ~p", [Event]),
    {next_state, wait_for_offline, State}.

wait_for_offline({set_last_waiting_acks, WAcks, NextMsgId}, _From, State) ->
    {reply, ok, wait_for_offline, handle_waiting_acks_and_msgs(WAcks, NextMsgId, State)};
wait_for_offline(
    {add_session, SessionPid, Opts},
    From,
    #state{waiting_call = {migrate, _OtherQueue, MigrationFrom}} = State
) ->
    %% Reason for this case:
    %% ---------------------
    %% This case handles a race condition that can happen when multiple
    %% concurrent clients (with clean_session=false) try to connect using
    %% the same client_id at the same time. The connect itself isn't necessarily
    %% the problem, as CONNECTs are synchronized using vmq_reg_sync. However
    %% faulty or dumb clients (with clean_session=false) that send a SUBSCRIBE
    %% every time after a CONNECT/CONNACK (e.g. not properly using the SessionPresent
    %% flag in returned CONNACK) may interfere with waiting migrate or add_session
    %% calls. The reason for this is that SUBSCRIBEs aren't synchronized while
    %% CONNECTs are.
    %%
    %% Precondition:
    %% -------------
    %% The calling session uses allow_register_during_netsplit=false for the session setup.
    %% The racing client are using clean_session=false
    %%
    %% Solution:
    %% ---------
    %% The waiting migration call isn't required anymore as we have a new session
    %% that can use this queue (and it's possible offline messages). As we haven't
    %% started to drain this queue (we are not in drain state) we can reply 'ok'
    %% to the waiting migration. The 'OtherQueue' that was part of the waiting
    %% migration gets eventually stopped.
    gen_fsm:reply(MigrationFrom, ok),
    {next_state, wait_for_offline, State#state{
        waiting_call = {add_session, SessionPid, Opts, From}
    }};
wait_for_offline(
    {add_session, NewSessionPid, NewOpts},
    From,
    #state{waiting_call = {add_session, SessionPid, _Opts, AddFrom}} = State
) ->
    %% Reason for this case:
    %% ---------------------
    %% See case above!
    %%
    %% Precondition:
    %% -------------
    %% See case above!
    %%
    %% Solution:
    %% ---------
    %% The waiting add_session call isn't required anymore as we have a new session
    %% that we should attach to this queue. We can terminate the waiting add_session
    %% and replace the waiting_call
    Opts = #{initial_msg_id => State#state.initial_msg_id},
    gen_fsm:reply(AddFrom, {ok, Opts}),
    exit(SessionPid, normal),
    {next_state, wait_for_offline, State#state{
        waiting_call = {add_session, NewSessionPid, NewOpts, From}
    }};
wait_for_offline(
    {add_session, _NewSessionPid, _NewOpts},
    _From,
    #state{waiting_call = {{cleanup, Reason}, _CleanupFrom}} = State
) ->
    %% Reason for this case:
    %% ---------------------
    %% a synchronized registration that had triggered a cleanup got
    %% superseded by a non-synchronized registration (e.g. allow_multiple_sessions=true)
    %%
    %% Solution:
    %% ---------
    %% We forcefully terminate the add_session call, as we have to ensure that
    %% this queue is completely wiped, before we allow new sessions to join.
    {reply, {error, {cleanup, Reason}}, wait_for_offline, State};
wait_for_offline(Event, _From, State) ->
    lager:error("got unknown sync event in wait_for_offline state ~p", [Event]),
    {reply, {error, wait_for_offline}, wait_for_offline, State}.

drain(
    drain_start,
    #state{
        id = SId,
        offline = #queue{queue = Q} = Queue,
        drain_time = DrainTimeout,
        max_msgs_per_drain_step = DrainStepSize,
        waiting_call = {migrate, RemoteQueue, _From}
    } = State
) ->
    {DrainQ, NewQ} = queue_split(DrainStepSize, Q),
    #queue{queue = DecompressedDrainQ} = decompress_queue(SId, #queue{queue = DrainQ}),
    case queue:to_list(DecompressedDrainQ) of
        [] ->
            %% no need to drain!

            %% the extra timeout gives the chance that pending messages
            %% in the erlang mailbox could still get enqueued and
            %% therefore eventually transmitted to the remote queue
            {next_state, drain, State#state{
                drain_over_timer = gen_fsm:send_event_after(DrainTimeout, drain_over),
                offline = Queue#queue{size = 0, drop = 0, queue = queue:new()}
            }};
        Msgs ->
            %% remote_enqueue triggers an enqueue_many inside the remote queue
            %% but forces the traffic to go over the distinct communication link
            %% instead of the erlang distribution link.
            ExtMsgs = lists:map(fun to_external/1, Msgs),
            {MRef, Ref} = vmq_cluster:remote_enqueue_async(
                node(RemoteQueue), {enqueue, RemoteQueue, ExtMsgs}, false
            ),
            {next_state, drain, State#state{
                offline = Queue#queue{size = queue:len(NewQ), drop = 0, queue = NewQ},
                drain_pending_batch = {MRef, Ref, DrainQ}
            }}
    end;
drain({enqueue, Msg}, #state{drain_over_timer = TRef} = State) ->
    %% even in drain state it is possible that an enqueue message
    %% reaches this process, so we've to queue this message otherwise
    %% it would be lost.
    gen_fsm:cancel_timer(TRef),
    gen_fsm:send_event(self(), drain_start),
    _ = vmq_metrics:incr_queue_in(),
    {next_state, drain, insert(Msg, State)};
drain(
    drain_over,
    #state{waiting_call = {migrate, _, From}} =
        #state{offline = #queue{size = 0}} = State
) ->
    %% we're done with the migrate, offline queue is empty
    gen_fsm:reply(From, ok),
    {stop, normal, State};
drain(drain_over, State) ->
    %% we still have undrained messages in the offline queue
    gen_fsm:send_event(self(), drain_start),
    {next_state, drain, State};
drain(Event, State) ->
    lager:error("got unknown event in drain state ~p", [Event]),
    {next_state, drain, State}.

drain({enqueue_many, Msgs}, _From, #state{drain_over_timer = TRef} = State) ->
    gen_fsm:cancel_timer(TRef),
    gen_fsm:send_event(self(), drain_start),
    _ = vmq_metrics:incr_queue_in(length(Msgs)),
    {reply, ok, drain, insert_many(Msgs, State)};
drain({enqueue_many, Msgs, Opts}, _From, #state{drain_over_timer = TRef} = State) ->
    gen_fsm:cancel_timer(TRef),
    gen_fsm:send_event(self(), drain_start),
    enqueue_many_(Msgs, drain, Opts, State);
drain({add_session, NewSessionPid, NewOpts}, From, State) ->
    lager:info("got add_session event from ~p for PID ~p with options ~p in drain state", [
        From, NewSessionPid, NewOpts
    ]),
    {reply, {error, draining}, drain, State};
drain(Event, _From, State) ->
    lager:error("got unknown sync event in drain state ~p", [Event]),
    {reply, {error, draining}, drain, State}.

offline(init_offline_queue, #state{id = SId} = State) ->
    case vmq_message_store:find(SId, queue_init) of
        {ok, MsgRefs} ->
            _ = vmq_metrics:incr_queue_initialized_from_storage(),
            {next_state, offline, insert_many(MsgRefs, maybe_set_expiry_timer(State))};
        {error, no_matching_hook_found} ->
            % that's ok
            _ = vmq_metrics:incr_queue_initialized_from_storage(),
            {next_state, offline, maybe_set_expiry_timer(State)};
        {error, Reason} ->
            lager:error("can't initialize queue from offline storage due to ~p, retry in 1 sec", [
                Reason
            ]),
            gen_fsm:send_event_after(1000, init_offline_queue),
            {next_state, offline, State}
    end;
offline({enqueue, Enq}, #state{id = SId} = State) ->
    case Enq of
        #deliver{
            qos = QoS,
            msg = #vmq_msg{
                routing_key = Topic,
                payload = Payload,
                retain = Retain
            }
        } ->
            _ = vmq_plugin:all(on_offline_message, [SId, QoS, Topic, Payload, Retain]);
        _ ->
            ignore
    end,
    %% storing the message in the offline queue
    _ = vmq_metrics:incr_queue_in(),
    {next_state, offline, insert(Enq, State)};
offline(expire_session, #state{id = SId, offline = #queue{queue = Q}} = State) ->
    %% session has expired cleanup and go down
    vmq_plugin:all(on_topic_unsubscribed, [SId, all_topics]),
    vmq_reg:delete_subscriptions(SId),
    cleanup_queue(SId, Q),
    _ = vmq_plugin:all(on_session_expired, [SId]),
    _ = vmq_metrics:incr_queue_unhandled(queue:len(Q)),
    State1 = publish_last_will(State),
    {stop, normal, State1};
offline(publish_last_will, State) ->
    State1 = unset_will_timer(publish_last_will(State)),
    {next_state, offline, State1};
offline(Event, State) ->
    lager:error("got unknown event in offline state ~p", [Event]),
    {next_state, offline, State}.
offline({add_session, SessionPid, Opts}, _From, State) ->
    ReturnOpts = #{initial_msg_id => State#state.initial_msg_id},
    {reply, {ok, ReturnOpts}, state_change(add_session, offline, online),
        unset_timers(add_session_(SessionPid, Opts, State))};
offline({migrate, OtherQueue}, From, State) ->
    gen_fsm:send_event(self(), drain_start),
    {next_state, state_change(migrate, offline, drain), State#state{
        waiting_call = {migrate, OtherQueue, From}
    }};
offline({enqueue_many, Msgs}, _From, State) ->
    _ = vmq_metrics:incr_queue_in(length(Msgs)),
    {reply, ok, offline, insert_many(Msgs, State)};
offline({enqueue_many, Msgs, Opts}, _From, State) ->
    enqueue_many_(Msgs, offline, Opts, State);
offline({cleanup, _Reason}, _From, #state{id = SId, offline = #queue{queue = Q}} = State) ->
    cleanup_queue(SId, Q),
    _ = vmq_metrics:incr_queue_unhandled(queue:len(Q)),
    {stop, normal, ok, State};
offline(Event, _From, State) ->
    lager:error("got unknown sync event in offline state ~p", [Event]),
    {reply, {error, offline}, offline, State}.

%%%===================================================================
%%% gen_fsm callbacks
%%%===================================================================

init([SubscriberId, Clean]) ->
    Defaults = default_opts(),
    #{
        max_offline_messages := MaxOfflineMsgs,
        queue_deliver_mode := DeliverMode,
        queue_type := QueueType,
        max_drain_time := DrainTime,
        max_msgs_per_drain_step := MaxMsgsPerDrainStep
    } = Defaults,
    OfflineQueue = #queue{type = QueueType, max = MaxOfflineMsgs},
    rand:seed(exsplus, os:timestamp()),
    case Clean of
        true ->
            ignore;
        false ->
            %% only init offline queue if this is a queue generated
            %% during broker startup or we were restarted by the
            %% vmq_queue_sup supervisor
            gen_fsm:send_event(self(), init_offline_queue)
    end,
    vmq_metrics:incr_queue_setup(),
    {ok, offline, #state{
        id = SubscriberId,
        offline = OfflineQueue,
        drain_time = DrainTime,
        deliver_mode = DeliverMode,
        max_msgs_per_drain_step = MaxMsgsPerDrainStep,
        opts = Defaults,
        started_at = vmq_time:timestamp(millisecond)
    }}.

handle_event(_Event, StateName, State) ->
    {next_state, StateName, State}.

handle_sync_event(
    status,
    _From,
    StateName,
    #state{
        deliver_mode = Mode,
        offline = #queue{size = OfflineSize},
        sessions = Sessions,
        opts = #{is_plugin := IsPlugin}
    } = State
) ->
    TotalStoredMsgs =
        maps:fold(
            fun(_, #session{queue = #queue{size = Size}}, Acc) ->
                Acc + Size
            end,
            OfflineSize,
            Sessions
        ),
    {reply, {StateName, Mode, TotalStoredMsgs, maps:size(Sessions), IsPlugin}, StateName, State};
handle_sync_event(
    info,
    _From,
    StateName,
    #state{
        deliver_mode = Mode,
        offline = #queue{size = OfflineSize},
        sessions = Sessions,
        opts = #{is_plugin := IsPlugin},
        started_at = StartedAt
    } = State
) ->
    {OnlineMessages, SessionInfo} =
        maps:fold(
            fun(
                _,
                #session{
                    pid = SessPid,
                    cleanup_on_disconnect = Clean,
                    queue = #queue{size = Size},
                    started_at = SessionStartedAt
                },
                {AccN, AccSess}
            ) ->
                {AccN + Size, [{SessPid, Clean, SessionStartedAt} | AccSess]}
            end,
            {0, []},
            Sessions
        ),
    Info = #{
        is_offline => (StateName == offline),
        is_online => (StateName /= offline),
        statename => StateName,
        deliver_mode => Mode,
        offline_messages => OfflineSize,
        online_messages => OnlineMessages,
        num_sessions => length(SessionInfo),
        is_plugin => IsPlugin,
        sessions => SessionInfo,
        started_at => StartedAt
    },
    {reply, Info, StateName, State};
handle_sync_event(get_sessions, _From, StateName, #state{sessions = Sessions} = State) ->
    {reply, maps:keys(Sessions), StateName, State};
handle_sync_event(get_opts, _From, StateName, #state{opts = Opts} = State) ->
    {reply, Opts, StateName, State};
handle_sync_event(
    {force_disconnect, Reason, DoCleanup},
    _From,
    StateName,
    #state{id = SId, sessions = Sessions, offline = #queue{queue = OfflineQ}} = State
) ->
    %% Forcefully disconnect all sessions and cleanup all state
    case DoCleanup of
        true ->
            vmq_plugin:all(on_topic_unsubscribed, [SId, all_topics]),
            vmq_reg:delete_subscriptions(SId),
            %% Collect all queues, make sure to include the backups
            SessionQueues = [
                queue:join(BQ, Q)
             || #session{queue = #queue{queue = Q, backup = BQ}} <- maps:values(Sessions)
            ],
            lists:foreach(
                fun(Q) ->
                    cleanup_queue(SId, Q),
                    _ = vmq_metrics:incr_queue_unhandled(queue:len(Q))
                end,
                [OfflineQ | SessionQueues]
            ),
            {stop, normal, ok, State};
        false ->
            disconnect_sessions(Reason, State),
            {reply, ok, StateName, State}
    end;
handle_sync_event({set_delayed_will, Fun, Delay}, _From, StateName, State) ->
    {reply, ok, StateName, State#state{delayed_will = {Delay, Fun}}};
handle_sync_event(Event, _From, _StateName, State) ->
    {stop, {error, {unknown_sync_event, Event}}, State}.

handle_info(
    {Ref, ok},
    drain,
    #state{
        id = SId,
        drain_pending_batch = {MRef, Ref, Batch}
    } = State
) ->
    %% remote async enqueue completed successfully.
    demonitor(MRef, [flush]),
    cleanup_queue(SId, Batch),
    _ = vmq_metrics:incr_queue_out(queue:len(Batch)),
    gen_fsm:send_event(self(), drain_start),
    {next_state, drain, State#state{drain_pending_batch = undefined}};
handle_info(
    {Ref, {error, not_reachable}},
    drain,
    #state{
        drain_pending_batch = {MRef, Ref, Batch},
        drain_time = DrainTimeout,
        offline = #queue{queue = Q}
    } = State
) ->
    %% remote async enqueue failed, let's retry
    demonitor(MRef, [flush]),
    gen_fsm:send_event_after(DrainTimeout, drain_start),
    {next_state, drain, State#state{
        drain_pending_batch = undefined,
        offline = #queue{queue = queue:join(Batch, Q)}
    }};
handle_info(
    {Ref, {error, Reason}},
    drain,
    #state{
        id = SId,
        drain_pending_batch = {MRef, Ref, Batch},
        offline = #queue{queue = Q},
        waiting_call = {migrate, RemoteQueue, From}
    } = State
) ->
    demonitor(MRef, [flush]),
    %% remote async enqueue failed, for another reason.  this
    %% shouldn't happen, as the register_subscriber is synchronized
    %% using the vmq_reg_leader process. However this could
    %% theoretically happen in case of an inconsistent (but
    %% un-detected) cluster state.  we don't drain in this case.
    lager:error(
        "can't drain queue '~p' for [~p][~p] due to ~p",
        [SId, self(), RemoteQueue, Reason]
    ),
    gen_fsm:reply(From, ok),
    %% transition to offline, and let a future session drain this queue
    {next_state, state_change(drain_error, drain, offline), State#state{
        waiting_call = undefined,
        drain_pending_batch = undefined,
        offline = #queue{queue = queue:join(Batch, Q)}
    }};
handle_info(
    {'DOWN', MRef, process, _, Reason},
    drain,
    #state{
        id = SId,
        drain_pending_batch = {MRef, _Ref, Batch},
        drain_time = DrainTimeout,
        offline = #queue{queue = Q},
        waiting_call = {migrate, RemoteQueue, _From}
    } = State
) ->
    lager:warning(
        "drain queue '~p' for [~p][~p] remote_enqueue failed due to ~p",
        [SId, self(), RemoteQueue, Reason]
    ),
    gen_fsm:send_event_after(DrainTimeout, drain_start),
    {next_state, drain, State#state{
        drain_pending_batch = undefined,
        offline = #queue{queue = queue:join(Batch, Q)}
    }};
handle_info({'DOWN', _MRef, process, Pid, _}, StateName, State) ->
    handle_session_down(Pid, StateName, State);
handle_info(Info, StateName, State) ->
    lager:error("got unknown handle_info in ~p state ~p", [StateName, Info]),
    {next_state, StateName, State}.

terminate(_Reason, _StateName, _State) ->
    vmq_metrics:incr_queue_teardown(),
    ok.

code_change(_OldVsn, StateName, State, _Extra) ->
    {ok, StateName, State}.

%%%===================================================================
%%% Internal functions
%%%===================================================================
enqueue_many_(Msgs, FsmState, #{states := AllowedStates}, State) ->
    case allowed_state(FsmState, AllowedStates) of
        true ->
            _ = vmq_metrics:incr_queue_in(length(Msgs)),
            {reply, ok, FsmState, insert_many(Msgs, State)};
        false ->
            {reply, {error, FsmState}, FsmState, State}
    end.

allowed_state(FsmState, AllowedStates) ->
    Any = lists:member(any, AllowedStates),
    Any orelse lists:member(FsmState, AllowedStates).

add_session_(
    SessionPid,
    Opts,
    #state{
        id = SId,
        offline = Offline,
        sessions = Sessions,
        opts = OldOpts
    } = State
) ->
    #{
        max_online_messages := MaxOnlineMessages,
        max_offline_messages := MaxOfflineMsgs,
        queue_deliver_mode := DeliverMode,
        queue_type := QueueType,
        cleanup_on_disconnect := Clean
    } = Opts,
    BatchSize = maps:get(queue_to_session_batch_size, Opts, 100),
    NewSessions =
        case maps:get(SessionPid, Sessions, not_found) of
            not_found ->
                _ = vmq_plugin:all(on_client_wakeup, [SId]),
                monitor(process, SessionPid),
                maps:put(
                    SessionPid,
                    #session{
                        pid = SessionPid,
                        cleanup_on_disconnect = Clean,
                        queue = #queue{max = MaxOnlineMessages},
                        started_at = vmq_time:timestamp(millisecond),
                        queue_to_session_batch_size = BatchSize
                    },
                    Sessions
                );
            _ ->
                Sessions
        end,
    insert_from_queue(
        Offline#queue{type = QueueType},
        State#state{
            deliver_mode = DeliverMode,
            offline = Offline#queue{
                max = MaxOfflineMsgs,
                type = QueueType,
                size = 0,
                drop = 0,
                queue = queue:new()
            },
            opts = maps:merge(OldOpts, Opts),
            sessions = NewSessions
        }
    ).

del_session(SessionPid, #state{id = SId, sessions = Sessions} = State) ->
    NewSessions = maps:remove(SessionPid, Sessions),
    case maps:get(SessionPid, Sessions) of
        #session{cleanup_on_disconnect = true} = Session ->
            cleanup_session(SId, Session),
            {State#state{sessions = NewSessions}, Session};
        Session ->
            %% give queue content of this session to other alive sessions
            %% or to offline queue
            {insert_from_session(Session, State#state{sessions = NewSessions}), Session}
    end.

handle_session_down(
    SessionPid,
    StateName,
    #state{id = SId, waiting_call = WaitingCall} = State
) ->
    {NewState, DeletedSession} = del_session(SessionPid, State),
    case {maps:size(NewState#state.sessions), StateName, WaitingCall} of
        {0, wait_for_offline, {add_session, NewSessionPid, Opts, From}} ->
            %% last session gone
            %% ... but we've a new session waiting
            %%     no need to go into offline state
            RetOpts = #{initial_msg_id => State#state.initial_msg_id},
            gen_fsm:reply(From, {ok, RetOpts}),
            case DeletedSession#session.cleanup_on_disconnect of
                true ->
                    _ = vmq_plugin:all(on_client_gone, [SId]);
                false ->
                    _ = vmq_plugin:all(on_client_offline, [SId])
            end,
            {next_state, state_change({'DOWN', add_session}, wait_for_offline, online),
                add_session_(NewSessionPid, Opts, NewState#state{waiting_call = undefined})};
        {0, wait_for_offline, {migrate, _, From}} when
            DeletedSession#session.cleanup_on_disconnect
        ->
            %% last session gone
            %% ... we dont need to migrate this one
            vmq_plugin:all(on_topic_unsubscribed, [SId, all_topics]),
            vmq_reg:delete_subscriptions(SId),
            _ = vmq_plugin:all(on_client_gone, [SId]),
            gen_fsm:reply(From, ok),
            {stop, normal, NewState};
        {0, wait_for_offline, {migrate, _, _}} ->
            %% last session gone
            %% ... but we've a migrate request waiting
            %%     go into drain state
            gen_fsm:send_event(self(), drain_start),
            _ = vmq_plugin:all(on_client_offline, [SId]),
            {next_state, state_change({'DOWN', migrate}, wait_for_offline, drain), NewState};
        {0, wait_for_offline, {{cleanup, _Reason}, From}} ->
            %% Forcefully cleaned up, we have to cleanup remaining offline messages
            %% we don't cleanup subscriptions!
            #state{offline = #queue{queue = Q}} = NewState,
            cleanup_queue(SId, Q),
            _ = vmq_metrics:incr_queue_unhandled(queue:len(Q)),
            gen_fsm:reply(From, ok),
            _ = vmq_plugin:all(on_client_gone, [SId]),
            {stop, normal, NewState};
        {0, _, _} when DeletedSession#session.cleanup_on_disconnect ->
            %% last session gone
            %% ... we've to cleanup and go down
            %%
            %% it is assumed that all attached sessions use the same
            %% clean session flag
            vmq_plugin:all(on_topic_unsubscribed, [SId, all_topics]),
            vmq_reg:delete_subscriptions(SId),
            _ = vmq_plugin:all(on_client_gone, [SId]),
            {stop, normal, NewState};
        {0, OldStateName, _} ->
            %% last session gone
            %% ... we've to stay around and store the messages
            %%     inside the offline queue
            _ = vmq_plugin:all(on_client_offline, [SId]),
            {next_state, state_change('DOWN', OldStateName, offline),
                maybe_set_last_will_timer(
                    maybe_set_expiry_timer(NewState#state{
                        offline = compress_queue(SId, NewState#state.offline)
                    })
                )};
        _ ->
            %% still one or more sessions online
            {next_state, StateName, NewState}
    end.

handle_waiting_acks_and_msgs(
    WAcks, NextMsgId, #state{id = SId, sessions = Sessions, offline = Offline} = State
) ->
    %% we can only handle the last waiting acks and msgs if this is
    %% the last session active for this queue.
    case maps:size(Sessions) of
        1 ->
            %% this is the last active session
            NewOfflineQueue =
                lists:foldl(
                    fun
                        (#deliver{msg = #vmq_msg{persisted = true} = Msg} = D, AccOffline) ->
                            queue_insert(
                                true,
                                D#deliver{msg = Msg#vmq_msg{persisted = false}},
                                AccOffline,
                                SId
                            );
                        (Msg, AccOffline) ->
                            queue_insert(true, Msg, AccOffline, SId)
                    end,
                    Offline,
                    WAcks
                ),
            State#state{offline = NewOfflineQueue, initial_msg_id = NextMsgId};
        N ->
            lager:debug("handle waiting acks for multiple sessions (~p) not possible", [N]),
            %% it doesn't make sense to keep the waiting acks around
            %% however depending on the balancing strategy it would
            %% make sense to re-enqueue messages for other active
            %% sessions --> TODO
            State
    end.

disconnect_sessions(Reason, #state{sessions = Sessions}) ->
    maps:fold(
        fun(SessionPid, #session{}, _) ->
            %% before the session is going to die it
            %% will send out LWT messages and will give
            %% us back the waiting acks and messages
            %% calling set_last_waiting_acks/2
            %% then the 'DOWN' message gets triggered
            %% finally deleting the session
            vmq_mqtt_fsm_util:send(SessionPid, {disconnect, Reason}),
            ok
        end,
        ok,
        Sessions
    ).

change_session_state(NewState, SessionPid, #state{id = SId, sessions = Sessions} = State) ->
    #session{queue = #queue{backup = Backup} = Queue} = Session = maps:get(SessionPid, Sessions),
    cleanup_queue(SId, Backup),
    _ = vmq_metrics:incr_queue_out(queue:len(Backup)),
    UpdatedSession = change_session_state_(
        NewState,
        SId,
        Session#session{queue = Queue#queue{backup = queue:new()}}
    ),
    NewSessions = maps:update(SessionPid, UpdatedSession, Sessions),
    State#state{sessions = NewSessions}.

%% in active state
change_session_state_(active, _SId, #session{status = active} = Session) ->
    Session;
change_session_state_(notify, _SId, #session{status = active} = Session) ->
    Session#session{status = notify};
%% in passive state
change_session_state_(notify, _SId, #session{status = passive, queue = #queue{size = 0}} = Session) ->
    Session#session{status = notify};
change_session_state_(notify, _SId, #session{status = passive} = Session) ->
    send_notification(Session);
change_session_state_(active, _SId, #session{status = passive, queue = #queue{size = 0}} = Session) ->
    Session#session{status = active};
change_session_state_(active, SId, #session{status = passive} = Session) ->
    send(SId, Session);
%% in notify state
change_session_state_(active, _SId, #session{status = notify, queue = #queue{size = 0}} = Session) ->
    Session#session{status = active};
change_session_state_(active, SId, #session{status = notify} = Session) ->
    send(SId, Session);
change_session_state_(notify, _SId, #session{status = notify} = Session) ->
    Session.

insert_from_session(
    #session{queue = Queue},
    #state{deliver_mode = fanout, sessions = Sessions} = State
) when
    Sessions == #{}
->
    %% all will go into offline queue
    insert_from_queue(Queue, State);
insert_from_session(_, #state{deliver_mode = fanout} = State) ->
    %% due to fanout other sessions have already received the messages
    State;
insert_from_session(
    #session{queue = Queue},
    #state{deliver_mode = balance} = State
) ->
    %% allow other sessions to balance the messages of the dead queue
    insert_from_queue(Queue, State).

insert_from_queue(#queue{type = fifo, queue = Q, backup = BQ}, State) ->
    insert_from_queue(fun queue:out/1, queue:out(queue:join(BQ, Q)), State);
insert_from_queue(#queue{type = lifo, queue = Q, backup = BQ}, State) ->
    insert_from_queue(fun queue:out_r/1, queue:out_r(queue:join(BQ, Q)), State).

insert_from_queue(F, {{value, Msg}, Q}, State) when is_tuple(Msg) ->
    insert_from_queue(F, F(Q), insert(Msg, State));
insert_from_queue(F, {{value, MsgRef}, Q}, State) when is_binary(MsgRef) ->
    insert_from_queue(F, F(Q), insert(MsgRef, State));
insert_from_queue(_F, {empty, _}, State) ->
    State.

insert_many(MsgsOrRefs, State) ->
    lists:foldl(
        fun(MsgOrRef, AccState) ->
            insert(MsgOrRef, AccState)
        end,
        State,
        MsgsOrRefs
    ).

%% Offline Queue
-spec insert(deliver() | msg_ref(), state()) -> state().
insert(#deliver{qos = 0}, #state{sessions = Sessions} = State) when
    Sessions == #{}
->
    %% no session online, skip message for QoS0 Subscription
    State;
insert(#deliver{msg = #vmq_msg{qos = 0}}, #state{sessions = Sessions} = State) when
    Sessions == #{}
->
    %% no session online, skip QoS0 message for QoS1 or QoS2 Subscription
    State;
insert(MsgOrRef, #state{id = SId, offline = Offline, sessions = Sessions} = State) when
    Sessions == #{}
->
    %% no session online, insert in offline queue
    State#state{offline = queue_insert(true, maybe_set_expiry_ts(MsgOrRef), Offline, SId)};
%% Online Queue
insert(MsgOrRef, #state{id = SId, deliver_mode = fanout, sessions = Sessions} = State) ->
    {NewSessions, _} = session_fold(
        SId, fun session_insert/3, maybe_set_expiry_ts(MsgOrRef), Sessions
    ),
    State#state{sessions = NewSessions};
insert(MsgOrRef, #state{id = SId, deliver_mode = balance, sessions = Sessions} = State) ->
    Pids = maps:keys(Sessions),
    RandomPid = lists:nth(rand:uniform(maps:size(Sessions)), Pids),
    RandomSession = maps:get(RandomPid, Sessions),
    {UpdatedSession, _} = session_insert(SId, RandomSession, maybe_set_expiry_ts(MsgOrRef)),
    State#state{sessions = maps:update(RandomPid, UpdatedSession, Sessions)}.

session_insert(SId, #session{status = active, queue = Q} = Session, MsgOrRef) ->
    {send(SId, Session#session{queue = queue_insert(false, MsgOrRef, Q, SId)}), MsgOrRef};
session_insert(SId, #session{status = passive, queue = Q} = Session, MsgOrRef) ->
    {Session#session{queue = queue_insert(false, MsgOrRef, Q, SId)}, MsgOrRef};
session_insert(SId, #session{status = notify, queue = Q} = Session, MsgOrRef) ->
    {send_notification(Session#session{queue = queue_insert(false, MsgOrRef, Q, SId)}), MsgOrRef}.

%% unlimited messages accepted
queue_insert(Offline, MsgOrRef, #queue{max = -1, size = Size, queue = Queue} = Q, SId) ->
    Q#queue{queue = queue:in(maybe_offline_store(Offline, SId, MsgOrRef), Queue), size = Size + 1};
%% tail drop in case of fifo
queue_insert(
    _Offline, MsgOrRef, #queue{type = fifo, max = Max, size = Size, drop = Drop} = Q, SId
) when
    Size >= Max
->
    on_message_drop_hook(SId, MsgOrRef, queue_full),
    vmq_metrics:incr_queue_drop(),
    maybe_offline_delete(SId, MsgOrRef),
    Q#queue{drop = Drop + 1};
%% drop oldest in case of lifo
queue_insert(
    Offline,
    MsgOrRef,
    #queue{type = lifo, max = Max, size = Size, queue = Queue, drop = Drop} = Q,
    SId
) when
    Size >= Max
->
    {{value, OldMsgOrRef}, NewQueue} = queue:out(Queue),
    on_message_drop_hook(SId, OldMsgOrRef, queue_full),
    vmq_metrics:incr_queue_drop(),
    maybe_offline_delete(SId, OldMsgOrRef),
    Q#queue{
        queue = queue:in(maybe_offline_store(Offline, SId, MsgOrRef), NewQueue), drop = Drop + 1
    };
%% normal enqueue
queue_insert(Offline, MsgOrRef, #queue{queue = Queue, size = Size} = Q, SId) ->
    Q#queue{queue = queue:in(maybe_offline_store(Offline, SId, MsgOrRef), Queue), size = Size + 1}.

send(
    SId,
    #session{
        pid = Pid,
        queue = Q,
        queue_to_session_batch_size = BatchSize
    } = Session
) ->
    Session#session{status = passive, queue = send(SId, Pid, BatchSize, Q)}.

send(SId, Pid, BatchSize, #queue{type = fifo, queue = Queue, size = Count, drop = Dropped} = Q) ->
    {Batch, NewQueue, NewCount} = prepare_msgs(SId, queue:new(), Queue, Count, BatchSize),
    Msgs = queue:to_list(Batch),
    vmq_mqtt_fsm_util:send(Pid, {mail, self(), Msgs, Count, Dropped}),
    Q#queue{queue = NewQueue, backup = Batch, size = NewCount, drop = 0};
send(SId, Pid, _BatchSize, #queue{type = lifo, queue = Queue, size = Count, drop = Dropped} = Q) ->
    Msgs = maybe_expire_msgs(SId, lists:reverse(queue:to_list(Queue))),
    vmq_mqtt_fsm_util:send(Pid, {mail, self(), Msgs, Count, Dropped}),
    Q#queue{queue = queue:new(), backup = Queue, size = 0, drop = 0}.

prepare_msgs(_SId, OQ, Q, QC, 0) ->
    {OQ, Q, QC};
prepare_msgs(SId, OQ, Q, QC, N) ->
    case queue:out(Q) of
        {{value, Msg}, NQ} ->
            case maybe_deref(SId, Msg) of
                {ok, NewMsg} ->
                    case maybe_expire_msg(SId, NewMsg) of
                        expired ->
                            prepare_msgs(SId, OQ, NQ, QC - 1, N);
                        NewMsg1 ->
                            NOQ = queue:in(NewMsg1, OQ),
                            prepare_msgs(SId, NOQ, NQ, QC - 1, N - 1)
                    end;
                {error, _} ->
                    prepare_msgs(SId, OQ, NQ, QC - 1, N)
            end;
        {empty, _} ->
            {OQ, Q, QC}
    end.

maybe_deref(SId, MsgRef) when is_binary(MsgRef) ->
    case vmq_message_store:read(SId, MsgRef) of
        {ok, #vmq_msg{qos = QoS} = Msg} ->
            {ok, #deliver{qos = QoS, msg = Msg}};
        {error, _} = E ->
            E
    end;
maybe_deref(_, Msg) ->
    {ok, Msg}.

send_notification(#session{pid = Pid} = Session) ->
    vmq_mqtt_fsm_util:send(Pid, {mail, self(), new_data}),
    Session#session{status = passive}.

cleanup_session(SubscriberId, #session{queue = #queue{queue = Q, backup = BQ}}) ->
    _ = vmq_metrics:incr_queue_unhandled(queue:len(Q)),
    %% it's possible that the backup queue isn't cleaned up yet.
    cleanup_queue(SubscriberId, queue:join(Q, BQ)).

%% optimization
cleanup_queue(_, {[], []}) -> ok;
cleanup_queue(SId, Queue) -> cleanup_queue_(SId, queue:out(Queue)).

cleanup_queue_(SId, {{value, #deliver{} = Msg}, NewQueue}) ->
    maybe_offline_delete(SId, Msg),
    cleanup_queue_(SId, queue:out(NewQueue));
cleanup_queue_(SId, {{value, {deliver_pubrel, _}}, NewQueue}) ->
    % no need to deref
    cleanup_queue_(SId, queue:out(NewQueue));
cleanup_queue_(SId, {{value, MsgRef}, NewQueue}) when is_binary(MsgRef) ->
    maybe_offline_delete(SId, MsgRef),
    cleanup_queue_(SId, queue:out(NewQueue));
cleanup_queue_(SId, {{value, {{qos2, _}, _}}, NewQueue}) ->
    cleanup_queue_(SId, queue:out(NewQueue));
cleanup_queue_(_, {empty, _}) ->
    ok.

session_fold(SId, Fun, Acc, Map) ->
    session_fold(SId, Fun, Acc, Map, maps:keys(Map)).

session_fold(SId, Fun, Acc, Map, [K | Rest]) ->
    {NewV, NewAcc} = Fun(SId, maps:get(K, Map), Acc),
    session_fold(SId, Fun, NewAcc, maps:update(K, NewV, Map), Rest);
session_fold(_, _, Acc, Map, []) ->
    {Map, Acc}.

maybe_set_expiry_timer(
    #state{
        sessions = Sessions,
        opts = Opts
    } = State
) when Sessions == #{} ->
    Duration =
        case Opts of
            #{session_expiry_interval := ExpiryInterval} ->
                ExpiryInterval;
            _ ->
                vmq_config:get_env(persistent_client_expiration, 0)
        end,
    maybe_set_expiry_timer(Duration, State);
maybe_set_expiry_timer(State) ->
    State.

maybe_set_expiry_timer(0, State) ->
    %% never expire
    State;
maybe_set_expiry_timer(ExpireAfter, State) when ExpireAfter > 0 ->
    Ref = gen_fsm:send_event_after(ExpireAfter * 1000, expire_session),
    State#state{expiry_timer = Ref}.

maybe_set_last_will_timer(#state{delayed_will = undefined} = State) ->
    State;
maybe_set_last_will_timer(#state{delayed_will = {Delay, _Fun}} = State) ->
    Ref = gen_fsm:send_event_after(Delay * 1000, publish_last_will),
    State#state{delayed_will_timer = Ref}.

publish_last_will(#state{delayed_will = undefined} = State) ->
    State;
publish_last_will(#state{delayed_will = {_, Fun}} = State) ->
    Fun(),
    unset_will_timer(State#state{delayed_will = undefined}).
maybe_offline_store(_, _, #deliver{msg = #vmq_msg{qos = 0, persisted = false} = _Msg} = D) ->
    % Don't store QoS 0 messages in the message store
    D;
maybe_offline_store(
    Offline,
    SubscriberId,
    #deliver{qos = QoS, msg = #vmq_msg{dup = IsDup, persisted = false, expiry_ts = ExpiryTs} = Msg} =
        D
) when QoS > 0 ->
    %% this function writes the message to the message store, in case the queue
    %% has no online session attached anymore (Offline = true) the queue can
    %% 'compress' the messages. Compressing is done by only keeping the message
    %% reference in the queue (the rest of the message is fetched from the
    %% message store during 'decompress'). However, the message store doesn't
    %% store all message properties, therefore the queue can't just 'compress'
    %% every message. The following properties aren't stored by the currently
    %% provided message store:
    %% - Message ID (required when storing a message with the DUP flag)
    %% - Expiry Timestamp (required when storing a message that should expire)
    PMsg = Msg#vmq_msg{persisted = true},
    case vmq_message_store:write(SubscriberId, PMsg) of
        ok when Offline and IsDup ->
            % No compress
            D#deliver{msg = PMsg};
        ok when Offline and (ExpiryTs =/= undefined) ->
            % No compress
            D#deliver{msg = PMsg};
        ok when Offline ->
            % Compress
            PMsg#vmq_msg.msg_ref;
        ok ->
            % No compress, we're still online
            D#deliver{msg = PMsg};
        {error, _} ->
            %% in case we cannot store the message we keep the
            %% full message structure around
            D
    end;
maybe_offline_store(true, _, #deliver{msg = #vmq_msg{persisted = true, dup = true}} = D) ->
    % we can't compress a DUP message as we'd lose the message id when compressing
    D;
maybe_offline_store(
    true, _, #deliver{msg = #vmq_msg{persisted = true, expiry_ts = ExpiryTs}} = D
) when ExpiryTs =/= undefined ->
    % we can't compress a message that has the expiry_ts set as we'd lose the expiry ts when compressing
    D;
maybe_offline_store(true, _, #deliver{msg = #vmq_msg{persisted = true} = Msg}) ->
    % Compress
    Msg#vmq_msg.msg_ref;
maybe_offline_store(_, _, MsgOrRef) ->
    MsgOrRef.

maybe_offline_delete(SubscriberId, #deliver{msg = #vmq_msg{persisted = true, msg_ref = MsgRef}}) ->
    _ = vmq_message_store:delete(SubscriberId, MsgRef),
    ok;
maybe_offline_delete(SubscriberId, MsgRef) when is_binary(MsgRef) ->
    _ = vmq_message_store:delete(SubscriberId, MsgRef),
    ok;
maybe_offline_delete(_, _) ->
    ok.

unset_timers(State) ->
    S1 = unset_expiry_timer(State),
    unset_will_timer(S1).

unset_will_timer(#state{delayed_will_timer = undefined} = State) ->
    State;
unset_will_timer(#state{delayed_will_timer = Ref} = State) ->
    gen_fsm:cancel_timer(Ref),
    State#state{delayed_will_timer = undefined}.

unset_expiry_timer(#state{expiry_timer = undefined} = State) ->
    State;
unset_expiry_timer(#state{expiry_timer = Ref} = State) ->
    gen_fsm:cancel_timer(Ref),
    State#state{expiry_timer = undefined}.

state_change(Msg, OldStateName, NewStateName) ->
    lager:debug("transition from ~p --> ~p because of ~p", [OldStateName, NewStateName, Msg]),
    NewStateName.

set_general_opts(
    #{
        queue_deliver_mode := DeliverMode,
        max_offline_messages := MaxOfflineMsgs,
        max_msgs_per_drain_step := MaxMsgsPerDrainStep
    },
    #state{offline = Offline} = State
) ->
    State#state{
        offline = Offline#queue{max = MaxOfflineMsgs},
        deliver_mode = DeliverMode,
        max_msgs_per_drain_step = MaxMsgsPerDrainStep
    }.

set_session_opts(
    SessionPid,
    #{
        max_online_messages := MaxOnlineMsgs,
        queue_type := Type,
        cleanup_on_disconnect := Clean
    },
    #state{sessions = Sessions} = State
) ->
    #session{queue = Queue} = Session = maps:get(SessionPid, Sessions),
    NewSessions = maps:update(
        SessionPid,
        Session#session{
            cleanup_on_disconnect = Clean,
            queue = Queue#queue{
                max = MaxOnlineMsgs,
                type = Type
            }
        },
        Sessions
    ),
    State#state{sessions = NewSessions}.

compress_queue(SId, #queue{queue = Q} = Queue) ->
    NewQueue = compress_queue(SId, queue:to_list(Q), []),
    Queue#queue{queue = NewQueue}.

compress_queue(_, [], Acc) ->
    queue:from_list(lists:reverse(Acc));
compress_queue(SId, [Msg | Rest], Acc) ->
    compress_queue(SId, Rest, [maybe_offline_store(true, SId, Msg) | Acc]).

decompress_queue(SId, #queue{queue = Q} = Queue) ->
    NewQueue = decompress_queue(SId, queue:to_list(Q), []),
    Queue#queue{queue = NewQueue}.

decompress_queue(_, [], Acc) ->
    queue:from_list(lists:reverse(Acc));
decompress_queue(SId, [MsgRef | Rest], Acc) when is_binary(MsgRef) ->
    case vmq_message_store:read(SId, MsgRef) of
        {ok, #vmq_msg{qos = QoS} = Msg} ->
            decompress_queue(
                SId,
                Rest,
                [#deliver{qos = QoS, msg = Msg#vmq_msg{persisted = false}} | Acc]
            );
        {error, Reason} ->
            lager:warning(
                "can't decompress queue item with msg_ref ~p for subscriber ~p due to ~p",
                [MsgRef, SId, Reason]
            ),
            decompress_queue(SId, Rest, Acc)
    end;
decompress_queue(SId, [#deliver{msg = Msg} = D | Rest], Acc) ->
    decompress_queue(SId, Rest, [D#deliver{msg = Msg#vmq_msg{persisted = false}} | Acc]);
decompress_queue(SId, [_ | Rest], Acc) ->
    decompress_queue(SId, Rest, Acc).

queue_split(N, Queue) ->
    NN =
        case queue:len(Queue) of
            L when L > N -> N;
            L -> L
        end,
    queue:split(NN, Queue).

maybe_set_expiry_ts(#deliver{msg = #vmq_msg{expiry_ts = {expire_after, ExpireAfter}} = Msg} = D) ->
    D#deliver{
        msg = Msg#vmq_msg{expiry_ts = {vmq_time:timestamp(second) + ExpireAfter, ExpireAfter}}
    };
maybe_set_expiry_ts(Msg) ->
    Msg.

on_message_drop_hook(
    SubscriberId,
    #deliver{
        msg = #vmq_msg{routing_key = RoutingKey, qos = QoS, payload = Payload, properties = Props}
    },
    Reason
) ->
    vmq_plugin:all(on_message_drop, [
        SubscriberId, fun() -> {RoutingKey, QoS, Payload, Props} end, Reason
    ]);
on_message_drop_hook(SubscriberId, MsgRef, Reason) when is_binary(MsgRef) ->
    Promise = fun() ->
        case vmq_message_store:read(SubscriberId, MsgRef) of
            {ok, #vmq_msg{
                routing_key = RoutingKey, qos = QoS, payload = Payload, properties = Props
            }} ->
                {RoutingKey, QoS, Payload, Props};
            _ ->
                error
        end
    end,
    vmq_plugin:all(on_message_drop, [SubscriberId, Promise, Reason]).

maybe_expire_msgs(SId, Msgs) ->
    lists:filtermap(
        fun(Msg) ->
            case maybe_expire_msg(SId, Msg) of
                expired -> false;
                NewMsg -> {true, NewMsg}
            end
        end,
        Msgs
    ).

maybe_expire_msg(_SId, #deliver{msg = #vmq_msg{expiry_ts = undefined}} = M) ->
    M;
maybe_expire_msg(
    SId,
    #deliver{msg = #vmq_msg{expiry_ts = {ExpiryTS, _}} = M} = D
) ->
    case vmq_time:is_past(ExpiryTS) of
        true ->
            on_message_drop_hook(SId, D, expired),
            vmq_metrics:incr_queue_msg_expired(1),
            expired;
        Remaining ->
            D#deliver{msg = M#vmq_msg{expiry_ts = {ExpiryTS, Remaining}}}
    end;
maybe_expire_msg(_SId, M) ->
    %%pubrels
    M.

to_internal({deliver, QoS, Msg}) ->
    #deliver{qos = QoS, msg = Msg};
to_internal(Msg) ->
    Msg.

to_external(#deliver{qos = QoS, msg = Msg}) ->
    {deliver, QoS, Msg}.
